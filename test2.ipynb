{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPart B. Productions\\n\\n<stmt> --> <block> | <if_stmt> | <while_loop> | <assignment>\\n<block> --> `{`{<stmt> `;` }`}`\\n<if_stmt>   -->  `maybe``(`<bool_stmt> `)`<stmt>[`probably ` <stmt>]\\n<do_while> --> `bing` <block> <while_loop>\\n<while_loop> -->  `bong``(`<bool_stmt>`)`<stmt>\\n<for_loop> --> `turtle``(`<bool_stmt>`)`<block>\\n<assignment> --> `set` <factor> `=` <expr>\\n<expr> --> <term> {(`+`|`-`)<term>}\\n<term> --> <factor>{(`*`|`/`|`%`)<factor>}\\n<factor> -->  `a` | `b`|`c`|`d`|`{ ` <expr> `}`\\n\\n\\n\\n\\nPart C. LL grammar\\n\\nAll the rules conform to the standard of LL Grammar. The pairwise disjointness test confirms conformity. \\nFor the rules to pass the test, the rules must not have left-hand recursion. \\nThis means that no two rules could have the same first statement because if they did, the program could go in different paths. \\nThis makes the grammar non-deterministic, thus making it ambiguous. For example, <assignment> and <factor> could both have the ‘set’ keyword in to ensure that both are variables. \\nHowever, this would cause the grammar to fail the pairwise disjointness test. Since all the rules have unique keywords, the grammar passes the test. \\nThus conforming to the standard of LL Grammar. \\n\\nPart D. Unambigious \\n\\nThe previous part effectively confirms the grammar is unambigious because there is no way for the grammar to generate a multiple paths for a program using this language.\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part B. Productions\n",
    "\n",
    "<stmt> --> <block> | <if_stmt> | <while_loop> | <assignment>\n",
    "<block> --> `{`{<stmt> `;` }`}`\n",
    "<if_stmt>   -->  `maybe``(`<bool_stmt> `)`<stmt>[`probably ` <stmt>]\n",
    "<do_while> --> `bing` <block> <while_loop>\n",
    "<while_loop> -->  `bong``(`<bool_stmt>`)`<stmt>\n",
    "<for_loop> --> `turtle``(`<bool_stmt>`)`<block>\n",
    "<assignment> --> `set` <factor> `=` <expr>\n",
    "<expr> --> <term> {(`+`|`-`)<term>}\n",
    "<term> --> <factor>{(`*`|`/`|`%`)<factor>}\n",
    "<factor> -->  `a` | `b`|`c`|`d`|`{ ` <expr> `}`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Part C. LL grammar\n",
    "\n",
    "All the rules conform to the standard of LL Grammar. The pairwise disjointness test confirms conformity. \n",
    "For the rules to pass the test, the rules must not have left-hand recursion. \n",
    "This means that no two rules could have the same first statement because if they did, the program could go in different paths. \n",
    "This makes the grammar non-deterministic, thus making it ambiguous. For example, <assignment> and <factor> could both have the ‘set’ keyword in to ensure that both are variables. \n",
    "However, this would cause the grammar to fail the pairwise disjointness test. Since all the rules have unique keywords, the grammar passes the test. \n",
    "Thus conforming to the standard of LL Grammar. \n",
    "\n",
    "Part D. Unambigious \n",
    "\n",
    "The previous part effectively confirms the grammar is unambigious because there is no way for the grammar to generate a multiple paths for a program using this language.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class turtle_tokens:\n",
    "    def __init__(self,filename:str):\n",
    "        # Takes filename from object and imports the file\n",
    "        self.filename = filename\n",
    "        self.tokens = []\n",
    "        self.current = 0\n",
    "        self.lexeme = ''\n",
    "        self.line = \"\"\n",
    "        self.f = open(self.filename, \"r\")\n",
    "        # Hash table of tokens and token codes\n",
    "        self.token_map = {'a':1,\n",
    "                        'b':2,\n",
    "                        'c':4,\n",
    "                        'd':8,\n",
    "                        'set':9,\n",
    "                        '+':10,\n",
    "                        '-':11,\n",
    "                        '*':12,\n",
    "                        '/':13,\n",
    "                        '%':14,\n",
    "                        '<':15,\n",
    "                        '>':16,\n",
    "                        '<=':17,\n",
    "                        '>=':18,\n",
    "                        '==':19,\n",
    "                        '!=':20,\n",
    "                        '=':21,\n",
    "                        '(':22,\n",
    "                        ')':22,\n",
    "                        '{':23,\n",
    "                        '}':23,\n",
    "                        ';':24,\n",
    "                        'x':25,\n",
    "                        'y':26,\n",
    "                        'z':27,\n",
    "                        'o':28,\n",
    "                        'p':29\n",
    "        \n",
    "        }\n",
    "    def getlines(self):\n",
    "        # Parses each line in the file\n",
    "        for line in self.f:\n",
    "            self.line = line\n",
    "            self.find_tokens()\n",
    "    def find_tokens(self): \n",
    "        # finds all the tokens in a line\n",
    "        while self.current<len(self.line):\n",
    "            if self.line[self.current] in self.token_map.keys:\n",
    "                self.lexeme = self.line[self.current]\n",
    "                if self.line[self.current] == '>':\n",
    "                    self.eeq()\n",
    "                            \n",
    "                elif self.line[self.current] == '<':\n",
    "                    self.eeq()\n",
    "                            \n",
    "                elif self.line[self.current] == '=':\n",
    "                    self.eeq()\n",
    "                \n",
    "                elif self.line[self.current] == '!':\n",
    "                    self.eeq()\n",
    "                else:\n",
    "                    self.tokens.append(self.token_map[self.lexeme])\n",
    "                    self.inc()\n",
    "            elif self.line[self.current] == 's':\n",
    "                self.setting()\n",
    "            elif self.line[self.current].isnumeric:\n",
    "                self.intHandler()\n",
    "                    \n",
    "            else:\n",
    "                self.error()\n",
    "            self.inc()\n",
    "    def inc(self):\n",
    "        # increments current\n",
    "       self.current+=1\n",
    "    def setting(self):\n",
    "        # checks if the lexume is a assignment\n",
    "        while(self.current <len(self.line)):\n",
    "            if self.lexeme == 'set':\n",
    "                self.inc()\n",
    "                if self.line(self.current) == '':\n",
    "                    self.inc()\n",
    "                    if self.line(self.current) == '`':\n",
    "                        self.inc()\n",
    "                        while self.line(self.current) != '`' and self.current < len(self.line):\n",
    "                           self.inc()\n",
    "                        if self.line(self.current) == '`':\n",
    "                            self.tokens.append(self.token_map[self.lexeme])\n",
    "                        else:\n",
    "                            self.error()\n",
    "            else:\n",
    "                self.inc()\n",
    "                self.lexeme += self.line(self.current)\n",
    "        pass\n",
    "    \n",
    "    def eeq(self):\n",
    "        # Checks to see if the operator is actually comparitive \n",
    "        self.inc()\n",
    "        if self.current <len(self.line):\n",
    "            if self.line(self.current) == '=':\n",
    "                self.lexeme += self.line(self.current)\n",
    "                self.tokens.append(self.token_map[self.lexeme])\n",
    "        else:\n",
    "            self.tokens.append(self.token_map[self.lexeme])\n",
    "        \n",
    "    def intHander(self):\n",
    "        # checks if the ints have a suffix  \n",
    "        while self.lexeme.isnumeric:\n",
    "            self.inc()\n",
    "            self.lexeme+=self.line(self.current)\n",
    "        if self.line(self.current) in self.token_map.keys:\n",
    "            self.tokens.append(self.token_map[self.line(self.current)]) \n",
    "        else:\n",
    "            self.error()\n",
    "            \n",
    "    def error():\n",
    "        # stops the program from running\n",
    "        raise ValueError\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class turtle_script:\n",
    "    def __init__(self,tokens:str):\n",
    "        \n",
    "        self.tokens = tokens\n",
    "        self.current = 0\n",
    "        self.currentToken = tokens[self.current]\n",
    "        \n",
    "    def getNextToken(self):\n",
    "        if self.current<len(self.tokens):\n",
    "            self.current+=1\n",
    "        self.currentToken = self.tokens[self.current]\n",
    "    def stmt(self):\n",
    "        # <stmt> --> <block> | <if_stmt> | <while_loop> | <assignment>\n",
    "        if self.currentToken == '{':\n",
    "            self.block()\n",
    "        elif self.currentToken == 'z':\n",
    "            self.if_stmt()\n",
    "        elif self.currentToken == 'o':\n",
    "            self.while_loop()\n",
    "        elif self.currentToken == 'set':\n",
    "            self.assignment()\n",
    "        else:\n",
    "            self.error()\n",
    "    def block(self):\n",
    "        # <block> --> `{`{<stmt> `;` }`}`\n",
    "        if self.currentToken == '{':\n",
    "            self.getNextToken()\n",
    "            while self.currentToken !='}':\n",
    "                self.stmt()\n",
    "                if self.currentToken == ';':\n",
    "                    self.getNextToken()\n",
    "                \n",
    "            self.getNextToken()\n",
    "            \n",
    "        else:\n",
    "            self.error()\n",
    "    def if_stmt(self):\n",
    "        # <if_stmt>   -->  `z``(`<bool_stmt> `)`<stmt>[`p` <stmt>]\n",
    "        if self.currentToken == 'z':\n",
    "            self.getNextToken()\n",
    "            if self.currentToken == '(':\n",
    "                self.getNextToken()\n",
    "                self.bool_stmt()\n",
    "                if self.currentToken == ')':\n",
    "                    self.getNextToken()\n",
    "                    self.stmt()\n",
    "                    if self.currentToken == 'p':\n",
    "                        self.getNextToken()\n",
    "                        self.stmt()\n",
    "            else:\n",
    "                self.error()\n",
    "    def do_while(self):\n",
    "        # <do_while> --> `x` <block> <while_loop>\n",
    "        if self.currentToken == 'x':\n",
    "            self.getNextToken()\n",
    "            self.block()\n",
    "            self.while_loop()\n",
    "        else:\n",
    "            self.error()\n",
    "        \n",
    "    def while_loop(self):\n",
    "        # <while_loop> -->  `o``(`<bool_stmt>`)`<stmt>\n",
    "        if self.currentToken == 'o':\n",
    "            self.getNextToken()\n",
    "            if self.currentToken == '(':\n",
    "                self.getNextToken()\n",
    "                self.bool_stmt()\n",
    "                if self.currentToken == ')':\n",
    "                    self.getNextToken()\n",
    "                    self.stmt()\n",
    "            else:\n",
    "                self.error()\n",
    "    def for_loop(self):\n",
    "        # <for_loop> --> `y``(`<bool_stmt>`)`<block>\n",
    "        if self.currentToken == 'y':\n",
    "            self.getNextToken()\n",
    "            if self.currentToken == '(':\n",
    "                self.getNextToken()\n",
    "                self.bool_stmt()\n",
    "                if self.currentToken == ')':\n",
    "                    self.getNextToken()\n",
    "                    self.block()\n",
    "            else:\n",
    "                self.error()\n",
    "    def assignment(self):\n",
    "        # <assignment> --> `set` `=` <expr>\n",
    "        if self.currentToken == 'set':\n",
    "            self.getNextToken()\n",
    "            if self.currentToken == '=':\n",
    "                self.getNextToken()\n",
    "                self.expr()\n",
    "            else:\n",
    "                self.error()\n",
    "    def expr(self):\n",
    "        # <expr> --> <term> {(`+`|`-`)<term>}\n",
    "        self.term()\n",
    "        while self.currentToken == '+' or self.currentToken == '-':\n",
    "            self.getNextToken()\n",
    "            self.term()\n",
    "    def term(self):\n",
    "        # <term> --> <factor>{(`*`|`/`|`%`)<factor>}\n",
    "        self.factor()\n",
    "        while self.currentToken == '*' or self.currentToken == '/'or self.currentToken == '%':\n",
    "            self.getNextToken()\n",
    "            self.factor()\n",
    "    def bool_stmt(self):\n",
    "        if self.currentToken == True or self.currentToken == False:\n",
    "            self.getNextToken()\n",
    "    def factor(self):\n",
    "        # <factor> --> `set` | `a` | `b`|`c`|`d`|`{`<expr>`}`\n",
    "        if self.currentToken == 'set' or self.currentToken == 'set' or self.currentToken == 'set' or self.currentToken == 'set' or self.currentToken == 'set':\n",
    "            self.getNextToken()\n",
    "        elif self.currentToken == '{':\n",
    "            self.getNextToken()\n",
    "\n",
    "    def error(self):\n",
    "        raise SyntaxError\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part f: Syntax Analyzer \n",
    "def findTokens(file):\n",
    "    tokens = []\n",
    "    t = turtle_tokens(filename = file)\n",
    "    t = t.find_tokens()\n",
    "    tokens = t.tokens\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryangarland/Desktop/Desktop - Ryan Garland's Tardis/Computer Science/PLC/test2/test2.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Part G: test files\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(findTokens(\u001b[39m\"\u001b[39;49m\u001b[39mturtle_code_1.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(findTokens(\u001b[39m\"\u001b[39m\u001b[39mturtle_code_2.txt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(findTokens(\u001b[39m\"\u001b[39m\u001b[39mturtle_code_3.txt\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;32m/Users/ryangarland/Desktop/Desktop - Ryan Garland's Tardis/Computer Science/PLC/test2/test2.ipynb Cell 5\u001b[0m in \u001b[0;36mfindTokens\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m t \u001b[39m=\u001b[39m turtle_tokens(filename \u001b[39m=\u001b[39m file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mfind_tokens()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tokens \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mtokens\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryangarland/Desktop/Desktop%20-%20Ryan%20Garland%27s%20Tardis/Computer%20Science/PLC/test2/test2.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tokens'"
     ]
    }
   ],
   "source": [
    "# Part G: test files\n",
    "print(findTokens(\"turtle_code_1.txt\"))\n",
    "print(findTokens(\"turtle_code_2.txt\"))\n",
    "print(findTokens(\"turtle_code_3.txt\"))\n",
    "print(findTokens(\"turtle_code_4.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "578750e02b17427b3fe40220db2a4b290b2430efb4cff6dff0901767966f4e19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
